{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9533f0-c800-4daa-b8cb-505ed7f4df2b",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "Due:  Tue December 3, 8:00am"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44773582-50fe-4d66-ba8e-03a368b350ea",
   "metadata": {},
   "source": [
    "## GPS and Hyperparameters\n",
    "\n",
    "This exercise consists of two parts: first, you are to combine global transformer attention (from the last exercise) with message-passing (from the second exercise). It is completely up to you how you combine those aspects, alternating between the two seems to be one of the best available options though. You may use (pure) message-passing layers from pytorch-geometric for this exercise (but obviously not layers like GPSConv that already combine things - especially since GPSConv differs significantly from the architecture in the GPS paper...).\n",
    "\n",
    "The second part of the exercise is to find a good model (with hyperparameters) for peptides-func. For this task, I want you to use the tool weights&biases (wandb.ai) and their \"sweep\" functionality. You can find example code for this below. Since we do not have access to your wandb accounts, please provide screenshots of your results and verify that these models are indeed good.\n",
    "\n",
    "For the hyperparameter tuning, you must perform this on your hybrid architecture. It might be interesting to see in how far the results (which parameters are important etc) differ between pure transformers, pure message-passing (possibly with VN), and hybrid approaches, although such an evaluation is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33633a0d-3859-4d10-b3f4-d27c390a5e5c",
   "metadata": {},
   "source": [
    "## Hybrid GPS-like architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8a2d74-2089-47eb-9f61-df4f8c2ee9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:00.918053Z",
     "start_time": "2024-12-01T12:52:55.009507Z"
    }
   },
   "outputs": [],
   "source": [
    "# your model code goes here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GINELayerWithVN(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super(GINELayerWithVN, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        self.edge_encoder = torch.nn.Linear(edge_dim, out_channels)\n",
    "        # Remove node_encoder from here\n",
    "        self.virtual_node_mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(out_channels, out_channels),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.edge_encoder.weight)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "        for m in self.virtual_node_mlp:\n",
    "            if isinstance(m, torch.nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, vn_embed, batch):\n",
    "        # x is already encoded via node_encoder in the main model\n",
    "        x = x.float()  # Ensure x is FloatTensor\n",
    "        edge_attr = edge_attr.float()  # Ensure edge_attr is FloatTensor\n",
    "        edge_attr = self.edge_encoder(edge_attr)\n",
    "\n",
    "        # Add virtual node embedding to node features\n",
    "        vn_expanded = vn_embed[batch]\n",
    "        x = x + vn_expanded\n",
    "\n",
    "        # Message Passing\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        # Update node embeddings\n",
    "        out = self.mlp(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        # Compute messages\n",
    "        return x_j + edge_attr\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "# Laplacian Positional Encodings (LapPE)\n",
    "def compute_laplace_pe(data, num_eigenvec=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    num_nodes = A.shape[0]\n",
    "    D = np.diag(np.array(A.sum(axis=1)).flatten())\n",
    "    L = D - A.todense()\n",
    "    L = torch.tensor(L, dtype=torch.float, device=device)\n",
    "    try:\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(L)\n",
    "    except RuntimeError:\n",
    "        eigenvalues, eigenvectors = torch.symeig(L, eigenvectors=True)\n",
    "    available_eigenvec = eigenvectors.shape[1] - 1\n",
    "    actual_num_eigenvec = min(num_eigenvec, available_eigenvec)\n",
    "    eigenvectors = eigenvectors[:, 1:1 + actual_num_eigenvec]\n",
    "    if actual_num_eigenvec < num_eigenvec:\n",
    "        pad_size = num_eigenvec - actual_num_eigenvec\n",
    "        padding = torch.zeros(eigenvectors.shape[0], pad_size, device=device)\n",
    "        eigenvectors = torch.cat([eigenvectors, padding], dim=1)\n",
    "    return eigenvectors  # Shape: (num_nodes, num_eigenvec)\n",
    "\n",
    "# Random Walk Structural Embeddings (RWSE)\n",
    "def compute_rwse(data, walk_length=10):\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "    A = nx.adjacency_matrix(G).astype(float)\n",
    "    A = A.todense()\n",
    "    num_nodes = A.shape[0]\n",
    "    A = torch.tensor(A, dtype=torch.float, device=device)\n",
    "    rw_features = []\n",
    "    A_power = A.clone()\n",
    "    for _ in range(walk_length):\n",
    "        diag = torch.diagonal(A_power)\n",
    "        rw_features.append(diag)\n",
    "        A_power = torch.matmul(A_power, A)\n",
    "    rwse = torch.stack(rw_features, dim=1)  # (num_nodes, walk_length)\n",
    "    return rwse  # Shape: (num_nodes, walk_length)\n",
    "\n",
    "# SignNet to ensure sign invariance\n",
    "class SignNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(SignNet, self).__init__()\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(in_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.phi(x) + self.phi(-x)\n",
    "\n",
    "# Graph Transformer Layer with Masking\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, dropout=0.1):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=in_dim, num_heads=num_heads, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(out_dim, in_dim)\n",
    "        self.norm1 = nn.LayerNorm(in_dim)\n",
    "        self.norm2 = nn.LayerNorm(in_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        # x: (sequence_length, batch_size, embed_dim)\n",
    "        attn_output, _ = self.self_attn(x, x, x, key_padding_mask=key_padding_mask)\n",
    "        x = x + attn_output\n",
    "        x = self.norm1(x)\n",
    "        linear_output = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        x = x + linear_output\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Updated GNN Model with Virtual Node, GINE Layers, and Graph Transformer\n",
    "class GNNWithVirtualNodeAndGINEAndTransformer(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10, num_heads=4):\n",
    "        super(GNNWithVirtualNodeAndGINEAndTransformer, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_features = hidden_features\n",
    "\n",
    "        # Node Encoder\n",
    "        self.node_encoder = nn.Linear(in_features, hidden_features)\n",
    "\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.transformer_layers = nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(GINELayerWithVN(\n",
    "                in_channels=hidden_features,\n",
    "                out_channels=hidden_features,\n",
    "                edge_dim=edge_attr_dim\n",
    "            ))\n",
    "            self.transformer_layers.append(GraphTransformerLayer(hidden_features, hidden_features, num_heads=num_heads))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.virtual_node_embedding = torch.nn.Embedding(1, hidden_features)\n",
    "        torch.nn.init.constant_(self.virtual_node_embedding.weight.data, 0)\n",
    "\n",
    "        self.mlp_virtual_node = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_features, hidden_features),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Positional Encodings\n",
    "        self.lap_pe_dim = lap_pe_dim\n",
    "        self.rwse_dim = rwse_dim\n",
    "        self.lap_pe_linear = nn.Linear(hidden_features, hidden_features)\n",
    "        self.rwse_linear = nn.Linear(rwse_dim, hidden_features)\n",
    "        self.signnet = SignNet(lap_pe_dim, hidden_features)\n",
    "\n",
    "        \n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, data):\n",
    "        # Apply node_encoder first\n",
    "        x = self.node_encoder(x)  # [num_nodes, hidden_features]\n",
    "        # Initialize positional encodings tensor\n",
    "        pos_enc = torch.zeros_like(x).to(device)  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Iterate over each graph in the batch\n",
    "        num_graphs = batch.max().item() + 1\n",
    "        for graph_id in range(num_graphs):\n",
    "            mask = (batch == graph_id)\n",
    "            num_nodes_graph = mask.sum().item()\n",
    "\n",
    "            # Extract node indices for the current graph\n",
    "            node_idx = torch.where(batch == graph_id)[0]\n",
    "\n",
    "            # Extract subgraph using pyg.utils.subgraph\n",
    "            sub_edge_index, sub_edge_attr = pyg.utils.subgraph(\n",
    "                node_idx,\n",
    "                edge_index,\n",
    "                edge_attr,\n",
    "                relabel_nodes=True,\n",
    "                num_nodes=x.size(0)\n",
    "            )\n",
    "\n",
    "            # Create sub_data\n",
    "            sub_data = pyg.data.Data(\n",
    "                x=x[node_idx],\n",
    "                edge_index=sub_edge_index,\n",
    "                edge_attr=sub_edge_attr\n",
    "            )\n",
    "\n",
    "            # Compute Positional Encodings for the sub-graph\n",
    "            lap_pe = compute_laplace_pe(sub_data, num_eigenvec=self.lap_pe_dim)\n",
    "            rwse = compute_rwse(sub_data, walk_length=self.rwse_dim)\n",
    "\n",
    "            # Apply SignNet to LapPE\n",
    "            lap_pe = self.signnet(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Linear transformation\n",
    "            lap_pe = self.lap_pe_linear(lap_pe)  # [num_nodes_graph, hidden_features]\n",
    "            rwse = self.rwse_linear(rwse)        # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Combine positional encodings\n",
    "            graph_pos_enc = lap_pe + rwse  # [num_nodes_graph, hidden_features]\n",
    "\n",
    "            # Assign to pos_enc\n",
    "            pos_enc[node_idx] = graph_pos_enc  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Add positional encodings to node features\n",
    "        x = x + pos_enc  # [num_nodes, hidden_features]\n",
    "\n",
    "        # Initialize virtual node embedding\n",
    "        batch_size = num_graphs\n",
    "        vn_embed = self.virtual_node_embedding.weight.repeat(batch_size, 1)  # [batch_size, hidden_features]\n",
    "\n",
    "        for conv, transformer in zip(self.convs, self.transformer_layers):\n",
    "            x = conv(x, edge_index, edge_attr, vn_embed, batch)  # [num_nodes, hidden_features]\n",
    "            x = F.relu(x)\n",
    "\n",
    "            # Update virtual node embedding\n",
    "            vn_aggr = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "            vn_embed = vn_embed + self.mlp_virtual_node(vn_aggr)  # [batch_size, hidden_features]\n",
    "             # Prepare for Graph Transformer\n",
    "            # Group node features by graph and pad\n",
    "            x_padded, mask = pyg.utils.to_dense_batch(x, batch)  # x_padded: [batch_size, max_num_nodes, hidden_features]\n",
    "\n",
    "            # Transpose to match expected input of Transformer\n",
    "            x_padded = x_padded.transpose(0, 1)  # x_padded: [max_num_nodes, batch_size, hidden_features]\n",
    "\n",
    "            # mask remains of shape [batch_size, max_num_nodes], which matches key_padding_mask\n",
    "            # Invert mask for key_padding_mask (True indicates positions to be masked)\n",
    "            key_padding_mask = ~mask  # [batch_size, max_num_nodes]\n",
    "            x_padded = transformer(x_padded, key_padding_mask=key_padding_mask)\n",
    "\n",
    "            # Transpose back\n",
    "            x_padded = x_padded.transpose(0, 1)  # x_padded: [batch_size, max_num_nodes, hidden_features]\n",
    "\n",
    "            # Flatten x_padded back to x\n",
    "            x = x_padded[mask]  # x: [num_nodes, hidden_features]\n",
    "\n",
    "\n",
    "        # Apply global mean pooling\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_features]\n",
    "        x = self.fc(x)  # [batch_size, out_features]\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625a8487-01eb-46c2-ace6-7211b900b406",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:00.922399Z",
     "start_time": "2024-12-01T12:53:00.919067Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e53b0ec0-7936-4b9c-884f-b126418135f5",
   "metadata": {},
   "source": [
    "# WandB hyperparameter tuning example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10328b2a-634d-4c8e-93a2-ae255ae1b28a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:00.926368Z",
     "start_time": "2024-12-01T12:53:00.923497Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric as pyg\n",
    "import torch_scatter\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8fe3f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Before using wandb, you need to create an account. Then you can login by pasting your API key when prompted. (just the key, nothing else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba8bfcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:02.886898Z",
     "start_time": "2024-12-01T12:53:00.927375Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpablo-jahnen\u001b[0m (\u001b[33mpablo-jahnen-university-of-g-ttingen\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652f0fe4-eef7-4f8d-9b1a-93f66d72839a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:02.893937Z",
     "start_time": "2024-12-01T12:53:02.888904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find device\n",
    "if torch.cuda.is_available(): # NVIDIA\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available(): # apple M1/M2\n",
    "    device = torch.device('mps') \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f973d525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:03.142541Z",
     "start_time": "2024-12-01T12:53:02.894944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/u12751_3626129/ipykernel_144077/3660967575.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cora_graph = torch.load('cora.pt')\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "\n",
    "\n",
    "class LocalPlanetoid(Planetoid):\n",
    "    def download(self):\n",
    "        # Skip the downloading step since files are already present locally\n",
    "        print(\"Skipping download step - using local files.\")\n",
    "\n",
    "# Use the custom loader\n",
    "cora = LocalPlanetoid(root='./dataset/cora', name='Cora')\n",
    "\n",
    "\n",
    "cora_graph = torch.load('cora.pt')\n",
    "cora_dense_adj = pyg.utils.to_dense_adj(cora_graph.edge_index).to(device)\n",
    "# cora_graph.x = cora_graph.x.unsqueeze(0) # Add an empty batch dimension. I needed that for compatibility with MolHIV later.\n",
    "cora_graph = cora_graph.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39becd27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:03.159325Z",
     "start_time": "2024-12-01T12:53:03.150446Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCNLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, activation=torch.nn.functional.relu):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.activation = activation\n",
    "        self.W: torch.Tensor = torch.nn.Parameter(torch.zeros(in_features, out_features))\n",
    "        torch.nn.init.kaiming_normal_(self.W) \n",
    "\n",
    "    def forward(self, H: torch.Tensor, edge_index: torch.Tensor):\n",
    "        out = H.clone()\n",
    "        out += torch_scatter.scatter_add(H[edge_index[0]], edge_index[1], dim=0)\n",
    "        out = out.matmul(self.W)\n",
    "        if self.activation:\n",
    "            out = self.activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baea114a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:03.170311Z",
     "start_time": "2024-12-01T12:53:03.160336Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(model, cora, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(cora_graph.x, cora_graph.edge_index)\n",
    "    correct = (outputs[mask].argmax(-1) == cora_graph.y[mask]).sum()\n",
    "    return int(correct) / int(mask.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6b356e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:03.180817Z",
     "start_time": "2024-12-01T12:53:03.171318Z"
    }
   },
   "outputs": [],
   "source": [
    "class GraphNet(torch.nn.Module):\n",
    "    def __init__(self, in_features:int, out_features:int, hidden_features:int, activation=torch.nn.functional.relu, dropout=0.1):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.activation = activation\n",
    "        if dropout>0:\n",
    "            self.dropout = torch.nn.Dropout(dropout)\n",
    "        else: \n",
    "            self.dropout = torch.nn.Identity()\n",
    "\n",
    "        self.layer_1 = GCNLayer(in_features=in_features, out_features=hidden_features)\n",
    "        self.layer_2 = GCNLayer(in_features=hidden_features, out_features=hidden_features, activation=self.activation)\n",
    "        self.layer_3 = GCNLayer(in_features=hidden_features, out_features=hidden_features, activation=self.activation)\n",
    "        self.dense1 = torch.nn.Linear(in_features=hidden_features, out_features=hidden_features)\n",
    "        self.dense2 = torch.nn.Linear(in_features=hidden_features, out_features=out_features)\n",
    "\n",
    "    def forward(self, H: torch.Tensor, edge_index: torch.Tensor):\n",
    "        out = self.layer_1(H, edge_index)\n",
    "        out = self.dropout(out)\n",
    "        out = self.layer_2(out, edge_index)\n",
    "        out = self.dropout(out)\n",
    "        H = self.layer_3(out, edge_index)\n",
    "        H = self.dropout(out)\n",
    "        out = self.dense1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.dense2(out)\n",
    "        # H = torch.softmax(H, dim=-1)\n",
    "        # out = torch.nn.functional.softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c03c9a",
   "metadata": {},
   "source": [
    "## WandB train function\n",
    "\n",
    "We make a few changes to our train function to enable wandb logging of hyperparameters and metrics. The train function is written to allow both manual runs and hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2071964d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T12:53:03.191404Z",
     "start_time": "2024-12-01T12:53:03.181826Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(config=None, project=None, notes=None):\n",
    "\n",
    "    with wandb.init(config=config, project=project, notes=notes): # Initialize a new wandb run\n",
    "        # By passing our config through wandb,\n",
    "        # a) it is automatically logged\n",
    "        # b) we can use wandb sweeps to optimize hyperparameters\n",
    "        config = wandb.config \n",
    "\n",
    "        model = GraphNet(\n",
    "            in_features=cora_graph.num_features, \n",
    "            out_features=cora.num_classes, \n",
    "            hidden_features=config.hidden_features, \n",
    "            dropout=config.dropout).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=0)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cora_graph.x, cora_graph.edge_index) # we run on everything\n",
    "\n",
    "            loss = criterion(outputs[cora_graph.train_mask], cora_graph.y[cora_graph.train_mask]) # but only propagate the loss for the train labels\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step() # update parameters\n",
    "            scheduler.step() # update the learning rate once per epoch\n",
    "\n",
    "            val_acc = get_accuracy(model, cora_graph, cora_graph.val_mask)\n",
    "            wandb.log({\"val_acc\": val_acc, \"loss\": loss.item()})\n",
    "\n",
    "            if epoch % 10 == 0 and not wandb.run.sweep_id:\n",
    "                # Only print information on individual runs, not on sweeps\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item()}, Val accuracy: {val_acc}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model, best_epoch, best_val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b173ddcf",
   "metadata": {},
   "source": [
    "## Manual training runs\n",
    "\n",
    "With wandb, you can still manually run your training loop with different hyperparameters as you are used to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d47a66b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-01T12:53:03.192409Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_153429-zezam3e2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/zezam3e2' target=\"_blank\">honest-disco-3</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/zezam3e2' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/zezam3e2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.5020477771759033, Val accuracy: 0.326\n",
      "Epoch 10, Loss: 0.3020159900188446, Val accuracy: 0.712\n",
      "Epoch 20, Loss: 0.03215000033378601, Val accuracy: 0.746\n",
      "Epoch 30, Loss: 0.02383781410753727, Val accuracy: 0.75\n",
      "Epoch 40, Loss: 0.0033544055186212063, Val accuracy: 0.742\n",
      "Epoch 50, Loss: 0.005790542345494032, Val accuracy: 0.744\n",
      "Epoch 60, Loss: 0.00042989462963305414, Val accuracy: 0.756\n",
      "Epoch 70, Loss: 0.00021563301561400294, Val accuracy: 0.758\n",
      "Epoch 80, Loss: 2.8039690732839517e-05, Val accuracy: 0.76\n",
      "Epoch 90, Loss: 0.00014632560487370938, Val accuracy: 0.76\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▃▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▂▁▅▄▇▇██████████████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00051</td></tr><tr><td>val_acc</td><td>0.76</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">honest-disco-3</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/zezam3e2' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/zezam3e2</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_153429-zezam3e2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model, best_model_epoch, best_val_acc = train(dict(\n",
    "    hidden_features=128,\n",
    "    lr=0.01,\n",
    "    dropout=0.1,\n",
    "    epochs=100\n",
    "), project=\"Cora_GraphNet\", notes=\"first trial\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9ca8b008be13",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0ad4db19a89dc",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd346675",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.76 (using model from epoch 27 with val acc 0.76)\n"
     ]
    }
   ],
   "source": [
    "test_acc = get_accuracy(best_model, cora_graph, cora_graph.test_mask)\n",
    "print(f\"Test acc: {test_acc:.2f} (using model from epoch {best_model_epoch} with val acc {best_val_acc:.2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baed50",
   "metadata": {},
   "source": [
    "## Hyperparameter Search\n",
    "\n",
    "But you can also perform a hyperparameter search using wandb sweeps, by specifying a hyperparameter config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be78650c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    # hyperparameter search methods, e.g. grid, random\n",
    "    'method': 'random',\n",
    "\n",
    "    # metric to optimize\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'   \n",
    "    },\n",
    "\n",
    "    # parameters to search\n",
    "    'parameters': {\n",
    "        'hidden_features': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'dropout': {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.5,\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [100, 200, 300]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb6ca89",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: x6p72eew\n",
      "Sweep URL: https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Cora_GraphNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32d0c7",
   "metadata": {},
   "source": [
    "You can click on the `Sweep URL` to get a nice visualization on how well different sets of hyperparameters perform and to see which are the best (click on the best run and then on Overview).\n",
    "\n",
    "The following cell performs 5 runs using the sweep configuration given above. You can call `wandb.agent` multiple times to produce more runs for the same sweep configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e588c3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pw52plhs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.11716056513489488\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_153556-pw52plhs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/pw52plhs' target=\"_blank\">silvery-sweep-1</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/pw52plhs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/pw52plhs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▆▄▄▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇█████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.87889</td></tr><tr><td>val_acc</td><td>0.594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silvery-sweep-1</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/pw52plhs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/pw52plhs</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_153556-pw52plhs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3k4l0f3v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.07764551886589482\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_153703-3k4l0f3v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/3k4l0f3v' target=\"_blank\">faithful-sweep-2</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/3k4l0f3v' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/3k4l0f3v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇▆▆▅█▃▆▄▃▅▄▅▃▄▃▂▄▄▄▅▃▃▃▃▄▄▃▃▄▄▂▃▄▂▃▂▃▃▁▅</td></tr><tr><td>val_acc</td><td>▇▇█▆▆▅▂▅▃▃▃▃▃▃▅▁▁▁▃▃▃▅▅▅▅▅▅▅▅▅▆▅▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.48589</td></tr><tr><td>val_acc</td><td>0.148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-sweep-2</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/3k4l0f3v' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/3k4l0f3v</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_153703-3k4l0f3v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eleyz8tn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4321268507896277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_153810-eleyz8tn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/eleyz8tn' target=\"_blank\">golden-sweep-3</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/eleyz8tn' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/eleyz8tn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▆▅██▃▃▄▅▄▅▁▁▂▂▃▃▃▂▂▁▄▂▂▅▄▃▃▂▃▃▂▂▃▂▂▁▁▃▅▃</td></tr><tr><td>val_acc</td><td>▁▂▂▂▃▇▇▆▅▅▅▆▇▇█▆▅▅▅▅▃▂▂▂▂▂▂▃▅▅▇▇▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.75434</td></tr><tr><td>val_acc</td><td>0.168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-3</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/eleyz8tn' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/eleyz8tn</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_153810-eleyz8tn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jpn7s393 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.0352439346379973\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_153917-jpn7s393</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/jpn7s393' target=\"_blank\">logical-sweep-4</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/jpn7s393' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/jpn7s393</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▇██▆▅▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▂▄▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.76009</td></tr><tr><td>val_acc</td><td>0.492</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-4</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/jpn7s393' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/jpn7s393</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_153917-jpn7s393/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ht90x13r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3797236856470923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_154025-ht90x13r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/ht90x13r' target=\"_blank\">glamorous-sweep-5</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/sweeps/x6p72eew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/ht90x13r' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/ht90x13r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅▅▄▅▂▄▄▁▅▇▅▆▂▁▅▅▃▃▅█▇▂▅▂▅▅▄▃▃▅▄▂▃▃▄▂▄▄▃▄</td></tr><tr><td>val_acc</td><td>▁▁▃▃▃▃▃▄▆▆▆▆▆▆▆█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>6.62609</td></tr><tr><td>val_acc</td><td>0.172</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-sweep-5</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/ht90x13r' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet/runs/ht90x13r</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_GraphNet</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_154025-ht90x13r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb03889b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Close the sweep, otherwise individual runs after the sweep will still be logged as part of it\n",
    "wandb.teardown() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5cd84-3220-44dc-a738-8b3702832dbb",
   "metadata": {},
   "source": [
    "# Cora dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d415faef-ffc9-42bd-987c-5f1ba71a2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    # hyperparameter search methods, e.g. grid, random\n",
    "    'method': 'random',\n",
    "\n",
    "    # metric to optimize\n",
    "    'metric': {\n",
    "        'name': 'val_acc',\n",
    "        'goal': 'maximize'   \n",
    "    },\n",
    "\n",
    "    # parameters to search\n",
    "    'parameters': {\n",
    "        'hidden_features': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'dropout': {\n",
    "            # a flat distribution between 0 and 0.1\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.0,\n",
    "            'max': 0.5,\n",
    "        },\n",
    "        'lr': {\n",
    "            'values': [0.001, 0.0001, 0.00001]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [100, 200, 300]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "431c19c8-90ed-439b-938d-24312f171667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 81l0n2cs\n",
      "Sweep URL: https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"Cora_Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f14cf483-5956-4273-b9b4-2603ee45f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphNet = GNNWithVirtualNodeAndGINEAndTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3053a8e9-0bbd-41ad-a7a2-a63190bd9574",
   "metadata": {},
   "source": [
    " in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10, num_heads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b004c1c-bb75-4158-8303-0e7ba2a45aca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LocalPlanetoid' object has no attribute 'edge_attr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_edge_features \u001b[38;5;241m=\u001b[39m \u001b[43mcora\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:318\u001b[0m, in \u001b[0;36mInMemoryDataset.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    315\u001b[0m         data_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()]\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(data_list)[key]\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    319\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LocalPlanetoid' object has no attribute 'edge_attr'"
     ]
    }
   ],
   "source": [
    "num_edge_features = cora.edge_attr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb113abd-521a-46d0-ab55-6244c3d4a7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None, project=None, notes=None):\n",
    "\n",
    "    with wandb.init(config=config, project=project, notes=notes): # Initialize a new wandb run\n",
    "        # By passing our config through wandb,\n",
    "        # a) it is automatically logged\n",
    "        # b) we can use wandb sweeps to optimize hyperparameters\n",
    "        config = wandb.config \n",
    "\n",
    "        model = GraphNet(\n",
    "            in_features=cora_graph.num_features,  \n",
    "            hidden_features=config.hidden_features,\n",
    "            out_features=cora.num_classes,\n",
    "            edge_attr_dim=num_edge_features\n",
    "            ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=0)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(cora_graph.x, cora_graph.edge_index) # we run on everything\n",
    "\n",
    "            loss = criterion(outputs[cora_graph.train_mask], cora_graph.y[cora_graph.train_mask]) # but only propagate the loss for the train labels\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step() # update parameters\n",
    "            scheduler.step() # update the learning rate once per epoch\n",
    "\n",
    "            val_acc = get_accuracy(model, cora_graph, cora_graph.val_mask)\n",
    "            wandb.log({\"val_acc\": val_acc, \"loss\": loss.item()})\n",
    "\n",
    "            if epoch % 10 == 0 and not wandb.run.sweep_id:\n",
    "                # Only print information on individual runs, not on sweeps\n",
    "                print(f\"Epoch {epoch}, Loss: {loss.item()}, Val accuracy: {val_acc}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model, best_epoch, best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aecf74aa-6e33-40c3-836e-dfd1489009d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jl9hiu1k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.20194812280820337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_164326-jl9hiu1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/jl9hiu1k' target=\"_blank\">smooth-sweep-1</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/jl9hiu1k' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/jl9hiu1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smooth-sweep-1</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/jl9hiu1k' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/jl9hiu1k</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_164326-jl9hiu1k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run jl9hiu1k errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run jl9hiu1k errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = GraphNet(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8rsi6qvr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4057392005700869\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_164433-8rsi6qvr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/8rsi6qvr' target=\"_blank\">sweepy-sweep-2</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/8rsi6qvr' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/8rsi6qvr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweepy-sweep-2</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/8rsi6qvr' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/8rsi6qvr</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_164433-8rsi6qvr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 8rsi6qvr errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 8rsi6qvr errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = GraphNet(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wmc3c2do with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2835873284295613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_164541-wmc3c2do</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/wmc3c2do' target=\"_blank\">toasty-sweep-3</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/wmc3c2do' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/wmc3c2do</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-sweep-3</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/wmc3c2do' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/wmc3c2do</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_164541-wmc3c2do/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run wmc3c2do errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run wmc3c2do errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = GraphNet(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lsmd9abj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.07076876982334657\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_164648-lsmd9abj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/lsmd9abj' target=\"_blank\">sandy-sweep-4</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/lsmd9abj' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/lsmd9abj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sandy-sweep-4</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/lsmd9abj' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/lsmd9abj</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_164648-lsmd9abj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run lsmd9abj errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run lsmd9abj errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = GraphNet(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uy6m10cz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2871656134731472\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_164755-uy6m10cz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/uy6m10cz' target=\"_blank\">playful-sweep-5</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/sweeps/81l0n2cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/uy6m10cz' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/uy6m10cz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">playful-sweep-5</strong> at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/uy6m10cz' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer/runs/uy6m10cz</a><br/> View project at: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/Cora_Transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241201_164755-uy6m10cz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run uy6m10cz errored:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "    self._function()\n",
      "  File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "    model = GraphNet(\n",
      "            ^^^^^^^^^\n",
      "TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run uy6m10cz errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/local/u12751_3621625/ipykernel_131109/845135264.py\", line 9, in train\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = GraphNet(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m TypeError: GNNWithVirtualNodeAndGINEAndTransformer.__init__() got an unexpected keyword argument 'dropout'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train, count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe1ac8-e161-4044-a40f-d8eddb179d68",
   "metadata": {},
   "source": [
    " in_features, hidden_features, out_features, edge_attr_dim, num_layers=5, lap_pe_dim=10, rwse_dim=10, num_heads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39370cb2b090800b",
   "metadata": {},
   "source": [
    "# Peptide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbd5fcc05d90fdbc",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Dataset size: 10873\n",
      "Train graphs: 8698\n",
      "Validation graphs: 1087\n",
      "Test graphs: 1088\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import LRGBDataset\n",
    "import wandb\n",
    "import copy\n",
    "\n",
    "\n",
    "# Detect device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the peptides-func dataset\n",
    "# Define a transform function\n",
    "def to_float(data):\n",
    "    data.x = data.x.float()\n",
    "    data.edge_attr = data.edge_attr.float()\n",
    "    return data\n",
    "\n",
    "# Load the dataset with the transform\n",
    "dataset = LRGBDataset(root='dataset/peptides-func', name='Peptides-func', transform=to_float)\n",
    "\n",
    "print(f'Dataset size: {len(dataset)}')\n",
    "\n",
    "# Determine the number of node features, edge features, and classes\n",
    "num_node_features = dataset.num_features\n",
    "num_edge_features = dataset[0].edge_attr.shape[1]\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# Shuffle the dataset\n",
    "torch.manual_seed(42)\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "# Split the dataset\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "num_total = len(dataset)\n",
    "num_train = int(num_total * train_ratio)\n",
    "num_val = int(num_total * val_ratio)\n",
    "\n",
    "train_dataset = dataset[:num_train]\n",
    "val_dataset = dataset[num_train:num_train + num_val]\n",
    "test_dataset = dataset[num_train + num_val:]\n",
    "\n",
    "print(f'Train graphs: {len(train_dataset)}')\n",
    "print(f'Validation graphs: {len(val_dataset)}')\n",
    "print(f'Test graphs: {len(test_dataset)}')\n",
    "\n",
    "# Create data loaders\n",
    "def create_data_loader(dataset, batch_size, shuffle):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "# We will create data loaders inside the train function\n",
    "# Your model class\n",
    "\n",
    "\n",
    "GraphNet = GNNWithVirtualNodeAndGINEAndTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61567a17ff43090",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train(config=None, project=None, notes=None):\n",
    "    with wandb.init(config=config, project=project, notes=notes):\n",
    "        config = wandb.config\n",
    "\n",
    "        model = GraphNet(\n",
    "            in_features=num_node_features,\n",
    "            hidden_features=config.hidden_features,\n",
    "            out_features=num_classes,\n",
    "            edge_attr_dim=num_edge_features,\n",
    "            num_layers=config.num_layers,\n",
    "            lap_pe_dim=config.lap_pe_dim,\n",
    "            rwse_dim=config.rwse_dim,\n",
    "            num_heads=config.num_heads\n",
    "        ).to(device)\n",
    "\n",
    "        # Print the GPU memory allocated by PyTorch\n",
    "        print(f\"GPU memory allocated after model initialization: {torch.cuda.memory_allocated()} bytes\")\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs, eta_min=0)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        best_model = None\n",
    "        best_val_acc = 0\n",
    "        best_epoch = 0\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = create_data_loader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "        val_loader = create_data_loader(val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "        test_loader = create_data_loader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            for data in train_loader:\n",
    "                data = data.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(data.x, data.edge_index, data.edge_attr, data.batch, data)\n",
    "                loss = criterion(outputs, data.y.squeeze())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            val_acc = evaluate(model, val_loader)\n",
    "            wandb.log({\"val_acc\": val_acc, \"loss\": total_loss / len(train_loader)})\n",
    "\n",
    "            if epoch % 10 == 0 and not wandb.run.sweep_id:\n",
    "                print(f\"Epoch {epoch}, Loss: {total_loss / len(train_loader):.4f}, Val accuracy: {val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_epoch = epoch\n",
    "                best_model = copy.deepcopy(model)\n",
    "\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # Evaluate on test set\n",
    "        test_acc = evaluate(best_model, test_loader)\n",
    "        wandb.log({\"test_acc\": test_acc})\n",
    "\n",
    "        print(f\"Best Epoch: {best_epoch}, Best Validation Accuracy: {best_val_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        return best_model, best_epoch, best_val_acc, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64b7de26f73826c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data.x, data.edge_index, data.edge_attr, data.batch, data)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            #print(f\"preds shape: {preds.shape}, data.y shape: {data.y.squeeze().shape}, num_graphs: {data.num_graphs}\")\n",
    "\n",
    "            \n",
    "            # Convert one-hot encoded labels to class indices\n",
    "            true_classes = data.y.argmax(dim=1)  # Shape: [32]\n",
    "\n",
    "            # Compare predictions with true class indices\n",
    "            correct += (preds == true_classes).sum().item()\n",
    "            total += data.num_graphs\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b47e3c6688bb1cc",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. lr uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: c3pjm5h9\n",
      "Sweep URL: https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/sweeps/c3pjm5h9\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {'name': 'val_acc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'hidden_features': {'values': [64, 128, 256]},\n",
    "        'num_layers': {'values': [3, 5, 7]},\n",
    "        'num_heads': {'values': [4, 8]},\n",
    "        'lap_pe_dim': {'values': [5, 10, 15]},\n",
    "        'rwse_dim': {'values': [5, 10, 15]},\n",
    "        'dropout': {'min': 0.0, 'max': 0.5},\n",
    "        'lr': {'min': 1e-4, 'max': 1e-2, 'distribution': 'log_uniform'},\n",
    "        'weight_decay': {'min': 0.0, 'max': 1e-4},\n",
    "        'batch_size': {'values': [16, 32, 64]},\n",
    "        'epochs': {'value': 100}\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='peptides-func-hyperparameter-tuning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5256d47b2847c3",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dq7ynkn6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.007275817739050172\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_features: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlap_pe_dim: 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 1.0006626067020934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trwse_dim: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 6.623786632384202e-05\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/vast-standard/home/pablo.jahnen/u12751/jupyterhub-gwdg/wandb/run-20241201_231732-dq7ynkn6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/runs/dq7ynkn6' target=\"_blank\">resilient-sweep-1</a></strong> to <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/sweeps/c3pjm5h9' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/sweeps/c3pjm5h9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/sweeps/c3pjm5h9' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/sweeps/c3pjm5h9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/runs/dq7ynkn6' target=\"_blank\">https://wandb.ai/pablo-jahnen-university-of-g-ttingen/peptides-func-hyperparameter-tuning/runs/dq7ynkn6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory allocated after model initialization: 47365632 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([63]), data.y shape: torch.Size([63, 10]), num_graphs: 63\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([63]), data.y shape: torch.Size([63, 10]), num_graphs: 63\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([63]), data.y shape: torch.Size([63, 10]), num_graphs: 63\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([63]), data.y shape: torch.Size([63, 10]), num_graphs: 63\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([63]), data.y shape: torch.Size([63, 10]), num_graphs: 63\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([64]), data.y shape: torch.Size([64, 10]), num_graphs: 64\n",
      "preds shape: torch.Size([63]), data.y shape: torch.Size([63, 10]), num_graphs: 63\n"
     ]
    }
   ],
   "source": [
    "wandb.login()  # Ensure you are logged in to WandB\n",
    "\n",
    "# Start the sweep agent\n",
    "wandb.agent(sweep_id, function=train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10150d70055e40b9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
